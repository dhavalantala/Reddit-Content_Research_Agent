{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd167fe7",
   "metadata": {},
   "source": [
    "We scrap the reddit post with Python and Selenium. But it become incredibly hard to do for a number of reasons. \n",
    "1. Reddit doesn't rellt want everybody scraping their website even thougn it's public data. \n",
    "2. Evn if you were scraping it manually then you would have to parse all of that data. You'd have to understand the structured of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "\n",
    "setup.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee582d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24df861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapshots.models import BrightDataSnapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRIGHT_DATA_REDDIT_SCRAPER_API_KEY = os.environ.get(\"BRIGHT_DATA_REDDIT_SCRAPER_API_KEY\")\n",
    "assert BRIGHT_DATA_REDDIT_SCRAPER_API_KEY is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crawl_headers():\n",
    "    return {\n",
    "\t\"Authorization\": f\"Bearer {BRIGHT_DATA_REDDIT_SCRAPER_API_KEY}\",\n",
    "\t\"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def perform_scrape_snapshot(subreddit_url, num_of_posts: int = 20):\n",
    "    url = \"https://api.brightdata.com/datasets/v3/trigger\"\n",
    "    dataset_id = \"gd_lvz8ah06191smkebj4\"\n",
    "    headers = get_crawl_headers()\n",
    "    params = {\n",
    "    \t\"dataset_id\": dataset_id,\n",
    "    \t\"include_errors\": \"true\",\n",
    "    \t\"type\": \"discover_new\",\n",
    "    \t\"discover_by\": \"subreddit_url\",\n",
    "    \t\"limit_per_input\": \"100\",\n",
    "    }\n",
    "    data = [\n",
    "    \t{\"url\": f\"{subreddit_url}\",\"sort_by\":\"Top\",\"sort_by_time\":\"Today\",\"num_of_posts\":num_of_posts},\n",
    "    ]\n",
    "    \n",
    "    response = requests.post(url, headers=headers, params=params, json=data)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    snapshot_id = data.get('snapshot_id')\n",
    "    BrightDataSnapshot.objects.create(\n",
    "        snapshot_id = snapshot_id,\n",
    "        dataset_id = dataset_id,\n",
    "        status=\"Unknown\"\n",
    "    )\n",
    "    return snapshot_id\n",
    "\n",
    "\n",
    "perform_scrape_snapshot(\"https://www.reddit.com/r/python\", num_of_posts=25)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c61df2",
   "metadata": {},
   "source": [
    "\"sd_mh26rkjnjg0u6fkq3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7950bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_id = \"sd_mh34c3v6hbr1havmj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snapshot_progress(snapshot_id: str) -> bool:\n",
    "    url = f\"https://api.brightdata.com/datasets/v3/progress/{snapshot_id}\"\n",
    "    headers = get_crawl_headers()\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    snapshot_id = data.get('snapshot_id')\n",
    "    dataset_id= data.get('dataset_id')\n",
    "    BrightDataSnapshot.objects.update_or_create(\n",
    "        snapshot_id=snapshot_id,\n",
    "        dataset_id=dataset_id,\n",
    "        defaults = {\n",
    "            \"status\": data.get('status')\n",
    "        }\n",
    "    )\n",
    "    return data.get('status') == 'ready'\n",
    "\n",
    "\n",
    "get_snapshot_progress(snapshot_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_snapshot(snapshot_id: str) -> dict:\n",
    "    url = f\"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}\"\n",
    "    headers = get_crawl_headers()\n",
    "    params = {\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "reddit_results = download_snapshot(snapshot_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02dd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reddit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_field_names = [field.name for field in RedditPost._meta.get_fields()]\n",
    "model_field_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc19ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_fields = ['id', 'post_id',\n",
    " 'url',\n",
    " 'description',\n",
    " 'comments',\n",
    " 'related_posts',\n",
    " 'community_name',\n",
    " 'num_upvotes',\n",
    " 'num_comments']\n",
    "\n",
    "valid_fields = [x for x in model_field_names if x not in skip_fields]\n",
    "valid_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "for thread in reddit_results:\n",
    "    post_id = thread.get(\"post_id\")\n",
    "    url = thread.get(\"url\")\n",
    "    update_data = {k:v for k, v in thread.items() if k in valid_fields}\n",
    "    print(post_id, url, update_data)\n",
    "    RedditPost.objects.update_or_create(\n",
    "        post_id=post_id,\n",
    "        url=url,\n",
    "        defaults=update_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc7ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
